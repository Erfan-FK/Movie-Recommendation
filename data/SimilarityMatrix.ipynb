{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFvI1wI4p5WX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSets/movies_data.csv')\n",
        "\n",
        "#Feature Selection\n",
        "features_df = movies_df[['originalTitle', 'genres', 'crew', 'overview']]\n",
        "\n",
        "features_df = features_df.applymap(lambda x: str(x).lower())\n",
        "\n",
        "features_df['genres'] = features_df['genres'].str.replace(',', ' ')\n",
        "features_df['crew'] = features_df['crew'].apply(lambda x: ' '.join(name.replace(' ', '') for name in x.split(',')))\n",
        "\n",
        "features_df['tag'] = (\n",
        "    features_df['originalTitle'] + ' ' +\n",
        "    features_df['overview'] + ' ' +\n",
        "    features_df['genres'] + ' ' +\n",
        "    features_df['crew']\n",
        ")\n",
        "\n",
        "# Drop rows with any missing values\n",
        "features_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "Ggte3D5sqEiK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "def textToWordRoots(text):\n",
        "    words = []\n",
        "\n",
        "    for word in text.split():\n",
        "      words.append(ps.stem(word))\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "metadata": {
        "id": "dtbWxZy8E8Zl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df['tag'] = features_df['tag'].apply(textToWordRoots)"
      ],
      "metadata": {
        "id": "e7P7ikCEKqUd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features=7000, stop_words='english')\n",
        "features_matrix = cv.fit_transform(features_df['tag']).toarray()"
      ],
      "metadata": {
        "id": "UhBFVbUs1M26"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = cosine_similarity(features_matrix)"
      ],
      "metadata": {
        "id": "LXdyGh7trumw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('similarity_matrix.npy', similarity_matrix)"
      ],
      "metadata": {
        "id": "fVN-h1n-HNUW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(movie_index, similarity_matrix, top_n=10):\n",
        "    similarity_scores = list(enumerate(similarity_matrix[movie_index]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    similarity_scores = similarity_scores[1:top_n+1]\n",
        "    movie_indices = [i[0] for i in similarity_scores]\n",
        "\n",
        "    return movie_indices"
      ],
      "metadata": {
        "id": "5PnVy0XYxTqi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_index(title, movies_df):\n",
        "    return movies_df[movies_df['originalTitle'].str.contains(title, case=False, na=False)].index[0]"
      ],
      "metadata": {
        "id": "5-2RalSXxepH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_title = \"shrek\"\n",
        "movie_index = get_movie_index(movie_title, movies_df)\n",
        "print(movie_index)\n",
        "recommended_indices = recommend(movie_index, similarity_matrix, 10)\n",
        "recommended_movies = movies_df.iloc[recommended_indices]['originalTitle'].tolist()\n",
        "\n",
        "print(\"Recommended movies for '{}':\".format(movie_title))\n",
        "print(recommended_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjd_RhWyK2e",
        "outputId": "81f43ef7-8ebf-41b8-e090-b02a020f189e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "Recommended movies for 'shrek':\n",
            "['Shrek 2', 'Shrek the Third', 'Shrek Forever After', 'The Addams Family 2', 'Shanghai Noon', 'The Princess and the Frog', 'Wish Dragon', 'Puss in Boots', 'Gong fu yu jia', 'Trolls']\n"
          ]
        }
      ]
    }
  ]
}